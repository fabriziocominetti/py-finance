{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Finance 7 - Investment Portfolio Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides ways to work with large multidimensional arrays\n",
    "import numpy as np \n",
    "# Allows for further data manipulation and analysis\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as web # Reads stock data \n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import matplotlib.dates as mdates # Styling dates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt # For defining dates\n",
    "import mplfinance as mpf # Matplotlib finance\n",
    "\n",
    "import time\n",
    "\n",
    "# Used to get data from a directory\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#Statsmodels is a great library we can use to run regressions.\n",
    "import statsmodels.api as sm\n",
    "# Seaborn extends the capabilities of Matplotlib\n",
    "import seaborn as sns\n",
    "# Used for calculating regressions\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates & Other Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to files\n",
    "PATH = \"../data/stock-list/\"\n",
    "\n",
    "# Start date defaults\n",
    "ST_YEAR = 2017\n",
    "ST_MONTH = 1\n",
    "ST_DAY = 1\n",
    "ST_DATE_STR = f\"{ST_YEAR}-{ST_MONTH}-{ST_DAY}\"\n",
    "ST_DATE_DATETIME = dt.datetime(ST_YEAR, ST_MONTH, ST_DAY)\n",
    "\n",
    "# End date defaults\n",
    "EN_YEAR = 2021\n",
    "EN_MONTH = 12\n",
    "EN_DAY = 31\n",
    "EN_DATE_STR = f\"{EN_YEAR}-{EN_MONTH}-{EN_DAY}\"\n",
    "EN_DATE_DATETIME = dt.datetime(EN_YEAR, EN_MONTH, EN_DAY)\n",
    "\n",
    "risk_free_rate = 0.0125 # Approximate 10 year bond rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Stock File Names in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in listdir(PATH) if isfile(join(PATH, x))]\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers\n",
    "\n",
    "tickers.sort()\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that Returns a Dataframe from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_csv(ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv', index_col='Date', \n",
    "                         parse_dates=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        # print(\"File Doesn't Exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Multiple Stocks in One Dataframe by Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = get_df_from_csv(x)\n",
    "        mask = (df.index >= sdate) & (df.index <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markowitz Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harry Markowitz proved that you could make what is called an efficient portfolio. That is a portfolio that optimizes return while also minimizing risk. We don't benefit from analyzing individual securities at the same rate as if we instead considered a portfolio of stocks.\n",
    "\n",
    "We do this by creating portfolios with stocks that are not correlated. We want to calculate expected returns by analyzing the returns of each stock multiplied by its weight.\n",
    "\n",
    "$w_1r_1 + w_2r_2 = r_p$\n",
    "\n",
    "The standard deviation of the portfolio is found this way. Sum multiple calculations starting by finding the product of the first securities weight squared times its standard deviation squared. The middle is 2 times the correlation coefficient between the stocks. And, finally add those to the weight squared times the standard deviation squared for the second security.\n",
    "\n",
    "$(w_1 \\sigma_1 + w_2 \\sigma_2)^2 = w_1^2 \\sigma_1^2 + 2w_1 \\sigma_1w_2 \\sigma_2 \\rho_1 + w_2^2 \\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting an Efficient Frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used the calculations made in part 4 of this course to pick the best performing\n",
    "# stocks in the main sectors in the year 2018 through 2019\n",
    "# I made slight changes in those situations that allowed me to pick companies I knew\n",
    "port_list = [\"GNRC\", \"DXCM\", \"AMD\", \"NFLX\", \"COST\", \"TGT\", \"AES\", \"MSCI\", \n",
    "             \"NEM\", \"AMT\", \"HES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df = merge_df_by_column_name('Adj Close',  '2018-01-01', \n",
    "                                  '2021-09-01', *port_list)\n",
    "mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Growth of Investment over Total Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mult_df / mult_df.iloc[0] * 100).plot(figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = np.log(mult_df / mult_df.shift(1))\n",
    "mean_ret = returns.mean() * 252 # 252 average trading days per year\n",
    "mean_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.cov() * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Random Weight Equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 11 random values that sum to 1\n",
    "weights = np.random.random(11)\n",
    "weights /= np.sum(weights)\n",
    "print('Weights :', weights)\n",
    "print('Total Weight :', np.sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Return of Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide return of portfolio using random weights over the whole dataset\n",
    "np.sum(weights * returns.mean()) * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Returns & Risk of 10000 Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = [] # Returns list\n",
    "p_vol = [] # Volatility list\n",
    "p_SR = [] # Sharpe Ratio list\n",
    "p_wt = [] # Stock weights list\n",
    "\n",
    "\n",
    "for x in range(10000):\n",
    "    # Generate random weights\n",
    "    p_weights = np.random.random(11)\n",
    "    p_weights /= np.sum(p_weights)\n",
    "    \n",
    "    # Add return using those weights to list\n",
    "    ret_1 = np.sum(p_weights * returns.mean()) * 252\n",
    "    p_ret.append(ret_1)\n",
    "    \n",
    "    # Add volatility or standard deviation to list\n",
    "    vol_1 = np.sqrt(np.dot(p_weights.T, np.dot(returns.cov() * 252, p_weights)))\n",
    "    p_vol.append(vol_1)\n",
    "    \n",
    "    # Get Sharpe ratio\n",
    "    SR_1 = (ret_1 - risk_free_rate) / vol_1\n",
    "    p_SR.append(SR_1)\n",
    "    \n",
    "    # Store the weights for each portfolio\n",
    "    p_wt.append(p_weights)\n",
    "    \n",
    "# Convert to Numpy arrays\n",
    "p_ret = np.array(p_ret)\n",
    "p_vol = np.array(p_vol)\n",
    "p_SR = np.array(p_SR)\n",
    "p_wt = np.array(p_wt)\n",
    "\n",
    "p_ret, p_vol, p_SR, p_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with returns and volatility\n",
    "ports = pd.DataFrame({'Return': p_ret, 'Volatility': p_vol})\n",
    "\n",
    "ports.plot(x='Volatility', y='Return', kind='scatter', figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People want to maximize returns while avoiding as much risk as possible. William Sharpe created the Sharpe Ratio to find the portfolio that provides the best return for the lowest amount of risk.\n",
    "\n",
    "*Sharpe Ratio* = $ \\frac{r_i - r_f}{\\sigma_i}$\n",
    "\n",
    "$r_f = $ Risk Free Rate\n",
    "\n",
    "$r_i = $ Rate of Return of the stock\n",
    "\n",
    "$\\sigma_i = $ Standard Deviation of the Stock\n",
    "\n",
    "As return increases so does the Sharpe Ratio, but as Standard Deviation increase the Sharpe Ratio decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the index of the largest Sharpe Ratio\n",
    "SR_idx = np.argmax(p_SR)\n",
    "\n",
    "# Find the ideal portfolio weighting at that index\n",
    "i = 0\n",
    "while i < 11:\n",
    "    print(\"Stock : %s : %2.2f\" % (port_list[i], (p_wt[4296][i] * 100)))\n",
    "    i += 1\n",
    "    \n",
    "# Find volatility of that portfolio\n",
    "print(\"\\nVolatility :\", p_vol[4296])\n",
    "      \n",
    "# Find return of that portfolio\n",
    "print(\"Return :\", p_ret[4296])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feac5ee11db6385b4c12b0947c117f22892e921fb5655ece65f725e09c2e67f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
