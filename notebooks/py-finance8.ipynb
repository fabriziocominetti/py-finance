{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Finance 8 - Modern Portfolio Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides ways to work with large multidimensional arrays\n",
    "import numpy as np \n",
    "# Allows for further data manipulation and analysis\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as web # Reads stock data \n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import matplotlib.dates as mdates # Styling dates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt # For defining dates\n",
    "import mplfinance as mpf # Matplotlib finance\n",
    "\n",
    "import time\n",
    "\n",
    "# Used to get data from a directory\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "#Statsmodels is a great library we can use to run regressions.\n",
    "import statsmodels.api as sm\n",
    "# Seaborn extends the capabilities of Matplotlib\n",
    "import seaborn as sns\n",
    "# Used for calculating regressions\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates & Other Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to files\n",
    "PATH = \"../data/stock-list/\"\n",
    "\n",
    "# Start date defaults\n",
    "S_YEAR = 2017\n",
    "S_MONTH = 1\n",
    "S_DAY = 1\n",
    "S_DATE_STR = f\"{ST_YEAR}-{ST_MONTH}-{ST_DAY}\"\n",
    "S_DATE_DATETIME = dt.datetime(S_YEAR, S_MONTH, S_DAY)\n",
    "\n",
    "# End date defaults\n",
    "EN_YEAR = 2021\n",
    "EN_MONTH = 12\n",
    "EN_DAY = 31\n",
    "EN_DATE_STR = f\"{EN_YEAR}-{EN_MONTH}-{EN_DAY}\"\n",
    "E_DATE_DATETIME = dt.datetime(E_YEAR, E_MONTH, E_DAY)\n",
    "\n",
    "risk_free_rate = 0.0125 # Approximate 10 year bond rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Stock File Names in a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in listdir(PATH) if isfile(join(PATH, x))]\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers\n",
    "\n",
    "tickers.sort()\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that Returns a Dataframe from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_csv(ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv', index_col='Date', \n",
    "                         parse_dates=True)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        # print(\"File Doesn't Exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Multiple Stocks in One Dataframe by Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = get_df_from_csv(x)\n",
    "        mask = (df.index >= sdate) & (df.index <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Markowitz Portfolio Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harry Markowitz proved that you could make what is called an efficient portfolio. That is a portfolio that optimizes return while also minimizing risk. We don't benefit from analyzing individual securities at the same rate as if we instead considered a portfolio of stocks.\n",
    "\n",
    "We do this by creating portfolios with stocks that are not correlated. We want to calculate expected returns by analyzing the returns of each stock multiplied by its weight.\n",
    "\n",
    "$w_1r_1 + w_2r_2 = r_p$\n",
    "\n",
    "The standard deviation of the portfolio is found this way. Sum multiple calculations starting by finding the product of the first securities weight squared times its standard deviation squared. The middle is 2 times the correlation coefficient between the stocks. And, finally add those to the weight squared times the standard deviation squared for the second security.\n",
    "\n",
    "$(w_1 \\sigma_1 + w_2 \\sigma_2)^2 = w_1^2 \\sigma_1^2 + 2w_1 \\sigma_1w_2 \\sigma_2 \\rho_1 + w_2^2 \\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting an Efficient Frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I added the top 30 for each sector. You can obviously add as many as \n",
    "# you like\n",
    "# Then to keep the portfolio smaller I eliminated stocks that had an \n",
    "# allocation less than 1% to get this final list\n",
    "# I showed in part 4 of this series how to get the top sector stocks\n",
    "port_list = [\"GNRC\", \"CPRT\", \"ODFL\", \n",
    "            \"AMD\", \"PAYC\",\n",
    "            \"CHTR\",\n",
    "            \"MKC\", \"PG\",\n",
    "            \"PGR\",\n",
    "            \"NEM\",\n",
    "            \"CCI\",\n",
    "            \"COG\"]\n",
    "num_stocks = len(port_list)\n",
    "num_stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df = merge_df_by_column_name('Adj Close',  '2018-01-01', \n",
    "                                  '2021-09-01', *port_list)\n",
    "mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Growth of Investment over Total Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mult_df / mult_df.iloc[0] * 100).plot(figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = np.log(mult_df / mult_df.shift(1))\n",
    "mean_ret = returns.mean() * 252 # 252 average trading days per year\n",
    "mean_ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.cov() * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Random Weight Equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 11 random values that sum to 1\n",
    "weights = np.random.random(11)\n",
    "weights /= np.sum(weights)\n",
    "print('Weights :', weights)\n",
    "print('Total Weight :', np.sum(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Return of Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide return of portfolio using random weights over the whole dataset\n",
    "np.sum(weights * returns.mean()) * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Returns & Risk of 10000 Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = [] # Returns list\n",
    "p_vol = [] # Volatility list\n",
    "p_SR = [] # Sharpe Ratio list\n",
    "p_wt = [] # Stock weights list\n",
    "\n",
    "\n",
    "for x in range(10000):\n",
    "    # Generate random weights\n",
    "    p_weights = np.random.random(num_stocks)\n",
    "    p_weights /= np.sum(p_weights)\n",
    "    \n",
    "    # Add return using those weights to list\n",
    "    ret_1 = np.sum(p_weights * returns.mean()) * 252\n",
    "    p_ret.append(ret_1)\n",
    "    \n",
    "    # Add volatility or standard deviation to list\n",
    "    vol_1 = np.sqrt(np.dot(p_weights.T, np.dot(returns.cov() * 252, p_weights)))\n",
    "    p_vol.append(vol_1)\n",
    "    \n",
    "    # Get Sharpe ratio\n",
    "    SR_1 = (ret_1 - risk_free_rate) / vol_1\n",
    "    p_SR.append(SR_1)\n",
    "    \n",
    "    # Store the weights for each portfolio\n",
    "    p_wt.append(p_weights)\n",
    "    \n",
    "# Convert to Numpy arrays\n",
    "p_ret = np.array(p_ret)\n",
    "p_vol = np.array(p_vol)\n",
    "p_SR = np.array(p_SR)\n",
    "p_wt = np.array(p_wt)\n",
    "\n",
    "p_ret, p_vol, p_SR, p_wt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with returns and volatility\n",
    "ports = pd.DataFrame({'Return': p_ret, 'Volatility': p_vol})\n",
    "\n",
    "ports.plot(x='Volatility', y='Return', kind='scatter', figsize=(16, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sharpe Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People want to maximize returns while avoiding as much risk as possible. William Sharpe created the Sharpe Ratio to find the portfolio that provides the best return for the lowest amount of risk.\n",
    "\n",
    "*Sharpe Ratio* = $ \\frac{r_i - r_f}{\\sigma_i}$\n",
    "\n",
    "$r_f = $ Risk Free Rate\n",
    "\n",
    "$r_i = $ Rate of Return of the stock\n",
    "\n",
    "$\\sigma_i = $ Standard Deviation of the Stock\n",
    "\n",
    "As return increases so does the Sharpe Ratio, but as Standard Deviation increase the Sharpe Ratio decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the index of the largest Sharpe Ratio\n",
    "SR_idx = np.argmax(p_SR)\n",
    "\n",
    "# Find the ideal portfolio weighting at that index\n",
    "i = 0\n",
    "while i < num_stocks:\n",
    "    print(\"Stock : %s : %2.2f\" % (port_list[i], (p_wt[SR_idx][i] * 100)))\n",
    "    i += 1\n",
    "    \n",
    "# Find volatility of that portfolio\n",
    "print(\"\\nVolatility :\", p_vol[SR_idx])\n",
    "      \n",
    "# Find return of that portfolio\n",
    "print(\"Return :\", p_ret[SR_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Number of Shares & Cost Based on Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to use a similar portfolio that has slightly easier percents to work with\n",
    "\n",
    "# Calculated Weighting\n",
    "# Stock : GNRC : 21.90 \n",
    "# Stock : CPRT : 15.63 \n",
    "# Stock : ODFL : 23.83\n",
    "# Stock : AMD : 11.09\n",
    "# Stock : PAYC : 1.86\n",
    "# Stock : CHTR : 3.55\n",
    "# Stock : MKC : 2.87\n",
    "# Stock : PG : 1.09\n",
    "# Stock : PGR : 2.86\n",
    "# Stock : NEM : 10.11\n",
    "# Stock : CCI : 4.34\n",
    "# Stock : COG : 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find percentage closest to 1 and use it as the basis for calculating all other shares Since PG is 1% : GNRC is 21.90 : Multiply cost of PG (118.20) by 22 (21.9 Rounded up) and then divide that by the cost of GNRC to get the shares to buy for GNRC\n",
    "\n",
    "118.20 22 = 2,600.4 / 102.01 = 25.49 (25 Shares) 102.01 =\n",
    "\n",
    "In situations in which prices don't work either discard stock or force 1 share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_shares(one_price, force_one, wts, prices):\n",
    "    # Gets number of stocks to analyze\n",
    "    num_stocks = len(wts)\n",
    "    \n",
    "    # Holds the number of shares for each\n",
    "    shares = []\n",
    "    \n",
    "    # Holds Cost of shares for each\n",
    "    cost_shares = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_stocks:\n",
    "        # Get max amount to spend on stock \n",
    "        max_price = one_price * wts[i]\n",
    "        \n",
    "        # Gets number of shares to buy and adds them to list\n",
    "        num_shares = int(max_price / prices[i])\n",
    "        \n",
    "        # If the user wants to force buying one share do it\n",
    "        if(force_one & (num_shares == 0)):\n",
    "            num_shares = 1\n",
    "        \n",
    "        shares.append(num_shares)\n",
    "        \n",
    "        # Gets cost of those shares and appends to list\n",
    "        cost = num_shares * prices[i]\n",
    "        cost_shares.append(cost)\n",
    "        i += 1\n",
    "        \n",
    "    return shares, cost_shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Portfolio Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_weighting(share_cost):\n",
    "    \n",
    "    # Holds weights for stocks\n",
    "    stock_wts = []\n",
    "    # All values summed\n",
    "    tot_val = sum(share_cost)\n",
    "    print(\"Total Investment :\", tot_val)\n",
    "    \n",
    "    for x in share_cost:\n",
    "        stock_wts.append(x / tot_val)\n",
    "    return stock_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns the Value of Portfolio by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_port_val_by_date(date, shares, tickers):\n",
    "    port_prices = merge_df_by_column_name('Adj Close',  date, \n",
    "                                  date, *port_list)\n",
    "    # Convert from dataframe to Python list\n",
    "    port_prices = port_df_start.values.tolist()\n",
    "    # Trick that converts a list of lists into a single list\n",
    "    port_prices = sum(port_prices, [])\n",
    "    return port_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximate Portfolio Weighting Based on Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_list = [\"GNRC\", \"CPRT\", \"ODFL\", \"AMD\", \"PAYC\", \"CHTR\", \"MKC\", \n",
    "             \"PG\", \"PGR\", \"NEM\", \"CCI\", \"COG\"]\n",
    "\n",
    "port_wts = [22, 16, 24, 11, 2, 4, 3, 1, 3, 10, 4, 1]\n",
    "\n",
    "# Get all stock prices on the starting date\n",
    "port_df_start = merge_df_by_column_name('Adj Close',  '2020-01-02', \n",
    "                                  '2020-01-02', *port_list)\n",
    "# Convert from dataframe to Python list\n",
    "port_prices = port_df_start.values.tolist()\n",
    "# Trick that converts a list of lists into a single list\n",
    "port_prices = sum(port_prices, [])\n",
    "\n",
    "# Calculated Weighting\n",
    "# Stock : GNRC : 21.90 \n",
    "# Stock : CPRT : 15.63 \n",
    "# Stock : ODFL : 23.83\n",
    "# Stock : AMD : 11.09\n",
    "# Stock : PAYC : 1.86\n",
    "# Stock : CHTR : 3.55\n",
    "# Stock : MKC : 2.87\n",
    "# Stock : PG : 1.09\n",
    "# Stock : PGR : 2.86\n",
    "# Stock : NEM : 10.11\n",
    "# Stock : CCI : 4.34\n",
    "# Stock : COG : 0.87\n",
    "\n",
    "tot_shares, share_cost = get_port_shares(118.20, True, port_wts, port_prices)\n",
    "print(\"Shares :\", tot_shares)\n",
    "print(\"Share Cost :\", share_cost)\n",
    "\n",
    "# Get list of weights for stocks\n",
    "stock_wts = get_port_weighting(share_cost)\n",
    "print(\"Stock Weights :\", stock_wts)\n",
    "\n",
    "# Get value at end of year\n",
    "get_port_val_by_date('2020-12-31', tot_shares, port_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feac5ee11db6385b4c12b0947c117f22892e921fb5655ece65f725e09c2e67f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
