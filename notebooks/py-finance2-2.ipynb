{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Finance 2 - Download every stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as web # Reads stock data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import mplfinance as mpf # Matplotlib finance\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to files\n",
    "path = \"../data/stock-list/\"\n",
    "\n",
    "# Start date defaults\n",
    "ST_YEAR = 2017\n",
    "ST_MONTH = 1\n",
    "ST_DAY = 3\n",
    "ST_DATE_STR = f\"{ST_YEAR}-{ST_MONTH}-{ST_DAY}\"\n",
    "ST_DATE_DATETIME = dt.datetime(ST_YEAR, ST_MONTH, ST_DAY)\n",
    "\n",
    "# End date defaults\n",
    "EN_YEAR = 2021\n",
    "EN_MONTH = 8\n",
    "EN_DAY = 19\n",
    "EN_DATE_STR = f\"{EN_YEAR}-{EN_MONTH}-{EN_DAY}\"\n",
    "EN_DATE_DATETIME = dt.datetime(EN_YEAR, EN_MONTH, EN_DAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stock file names in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'AA',\n",
       " 'AAL',\n",
       " 'AAME',\n",
       " 'AAN',\n",
       " 'AAOI',\n",
       " 'AAON',\n",
       " 'AAP',\n",
       " 'AAPL',\n",
       " 'AAT',\n",
       " 'AAWW',\n",
       " 'ABBV',\n",
       " 'ABC',\n",
       " 'ABCB',\n",
       " 'ABEO',\n",
       " 'ABG',\n",
       " 'ABIO',\n",
       " 'ABM',\n",
       " 'ABMD',\n",
       " 'ABR',\n",
       " 'ABT',\n",
       " 'ABTX',\n",
       " 'AC',\n",
       " 'ACA',\n",
       " 'ACAD',\n",
       " 'ACBI',\n",
       " 'ACC',\n",
       " 'ACCO',\n",
       " 'ACER',\n",
       " 'ACGL',\n",
       " 'ACHC',\n",
       " 'ACHV',\n",
       " 'ACIW',\n",
       " 'ACLS',\n",
       " 'ACM',\n",
       " 'ACMR',\n",
       " 'ACN',\n",
       " 'ACNB',\n",
       " 'ACOR',\n",
       " 'ACRE',\n",
       " 'ACRS',\n",
       " 'ACRX',\n",
       " 'ACTG',\n",
       " 'ACU',\n",
       " 'ACY',\n",
       " 'ADBE',\n",
       " 'ADC',\n",
       " 'ADES',\n",
       " 'ADI',\n",
       " 'ADM',\n",
       " 'ADMA',\n",
       " 'ADMP',\n",
       " 'ADNT',\n",
       " 'ADP',\n",
       " 'ADS',\n",
       " 'ADSK',\n",
       " 'ADT',\n",
       " 'ADTN',\n",
       " 'ADUS',\n",
       " 'ADVM',\n",
       " 'ADXS',\n",
       " 'AE',\n",
       " 'AEE',\n",
       " 'AEHR',\n",
       " 'AEIS',\n",
       " 'AEL',\n",
       " 'AEMD',\n",
       " 'AEO',\n",
       " 'AEP',\n",
       " 'AERI',\n",
       " 'AES',\n",
       " 'AEY',\n",
       " 'AFG',\n",
       " 'AFI',\n",
       " 'AFL',\n",
       " 'AGCO',\n",
       " 'AGE',\n",
       " 'AGEN',\n",
       " 'AGFS',\n",
       " 'AGIO',\n",
       " 'AGLE',\n",
       " 'AGM',\n",
       " 'AGNC',\n",
       " 'AGO',\n",
       " 'AGR',\n",
       " 'AGRX',\n",
       " 'AGS',\n",
       " 'AGTC',\n",
       " 'AGX',\n",
       " 'AGYS',\n",
       " 'AHH',\n",
       " 'AHT',\n",
       " 'AIG',\n",
       " 'AIMC',\n",
       " 'AIN',\n",
       " 'AINC',\n",
       " 'AIR',\n",
       " 'AIRG',\n",
       " 'AIRI',\n",
       " 'AIRT',\n",
       " 'AIT',\n",
       " 'AIV',\n",
       " 'AIZ',\n",
       " 'AJG',\n",
       " 'AJRD',\n",
       " 'AJX',\n",
       " 'AKAM',\n",
       " 'AKBA',\n",
       " 'AKR',\n",
       " 'AKTS',\n",
       " 'AL',\n",
       " 'ALB',\n",
       " 'ALBO',\n",
       " 'ALCO',\n",
       " 'ALDX',\n",
       " 'ALE',\n",
       " 'ALEC',\n",
       " 'ALEX',\n",
       " 'ALG',\n",
       " 'ALGN',\n",
       " 'ALGT',\n",
       " 'ALIM',\n",
       " 'ALJJ',\n",
       " 'ALK',\n",
       " 'ALKS',\n",
       " 'ALL',\n",
       " 'ALLE',\n",
       " 'ALLK',\n",
       " 'ALLO',\n",
       " 'ALLY',\n",
       " 'ALNA',\n",
       " 'ALNY',\n",
       " 'ALOT',\n",
       " 'ALPN',\n",
       " 'ALRM',\n",
       " 'ALSN',\n",
       " 'ALT',\n",
       " 'ALTR',\n",
       " 'ALV',\n",
       " 'ALX',\n",
       " 'AM',\n",
       " 'AMAL',\n",
       " 'AMAT',\n",
       " 'AMBC',\n",
       " 'AMC',\n",
       " 'AMCX',\n",
       " 'AMD',\n",
       " 'AME',\n",
       " 'AMED',\n",
       " 'AMG',\n",
       " 'AMGN',\n",
       " 'AMH',\n",
       " 'AMKR',\n",
       " 'AMN',\n",
       " 'AMNB',\n",
       " 'AMOT',\n",
       " 'AMP',\n",
       " 'AMPE',\n",
       " 'AMPH',\n",
       " 'AMRC',\n",
       " 'AMRK',\n",
       " 'AMRS',\n",
       " 'AMRX',\n",
       " 'AMS',\n",
       " 'AMSC',\n",
       " 'AMSF',\n",
       " 'AMSWA',\n",
       " 'AMT',\n",
       " 'AMTD',\n",
       " 'AMTX',\n",
       " 'AMWD',\n",
       " 'AMZN',\n",
       " 'AN',\n",
       " 'ANAB',\n",
       " 'ANAT',\n",
       " 'ANDE',\n",
       " 'ANET',\n",
       " 'ANF',\n",
       " 'ANGI',\n",
       " 'ANGO',\n",
       " 'ANIK',\n",
       " 'ANIP',\n",
       " 'ANIX',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'AOS',\n",
       " 'AOSL',\n",
       " 'AP',\n",
       " 'APA',\n",
       " 'APAM',\n",
       " 'APD',\n",
       " 'APDN',\n",
       " 'APEI',\n",
       " 'APEN',\n",
       " 'APH',\n",
       " 'APLE',\n",
       " 'APLS',\n",
       " 'APOG',\n",
       " 'APPF',\n",
       " 'APPN',\n",
       " 'APPS',\n",
       " 'APRN',\n",
       " 'APT',\n",
       " 'APTS',\n",
       " 'APTV',\n",
       " 'APVO',\n",
       " 'APYX',\n",
       " 'AQB',\n",
       " 'AQMS',\n",
       " 'AQUA',\n",
       " 'AR',\n",
       " 'ARAV',\n",
       " 'ARAY',\n",
       " 'ARC',\n",
       " 'ARCB',\n",
       " 'ARCH',\n",
       " 'ARDX',\n",
       " 'ARE',\n",
       " 'ARES',\n",
       " 'ARGO',\n",
       " 'ARI',\n",
       " 'ARKR',\n",
       " 'ARL',\n",
       " 'ARLO',\n",
       " 'ARMK',\n",
       " 'ARNA',\n",
       " 'ARNC',\n",
       " 'AROC',\n",
       " 'AROW',\n",
       " 'ARR',\n",
       " 'ARTNA',\n",
       " 'ARTW',\n",
       " 'ARVN',\n",
       " 'ARW',\n",
       " 'ARWR',\n",
       " 'ASB',\n",
       " 'ASGN',\n",
       " 'ASH',\n",
       " 'ASIX',\n",
       " 'ASMB',\n",
       " 'ASPN',\n",
       " 'ASPS',\n",
       " 'ASRT',\n",
       " 'ASRV',\n",
       " 'ASTC',\n",
       " 'ASTE',\n",
       " 'ASUR',\n",
       " 'ASYS',\n",
       " 'ATEC',\n",
       " 'ATEN',\n",
       " 'ATGE',\n",
       " 'ATHX',\n",
       " 'ATI',\n",
       " 'ATKR',\n",
       " 'ATLC',\n",
       " 'ATLO',\n",
       " 'ATNI',\n",
       " 'ATNM',\n",
       " 'ATNX',\n",
       " 'ATO',\n",
       " 'ATOS',\n",
       " 'ATR',\n",
       " 'ATRA',\n",
       " 'ATRC',\n",
       " 'ATRI',\n",
       " 'ATRO',\n",
       " 'ATRS',\n",
       " 'ATSG',\n",
       " 'ATUS',\n",
       " 'ATVI',\n",
       " 'AUBN',\n",
       " 'AUMN',\n",
       " 'AUTO',\n",
       " 'AVA',\n",
       " 'AVAV',\n",
       " 'AVB',\n",
       " 'AVD',\n",
       " 'AVEO',\n",
       " 'AVGO',\n",
       " 'AVGR',\n",
       " 'AVID',\n",
       " 'AVLR',\n",
       " 'AVNS',\n",
       " 'AVNW',\n",
       " 'AVRO',\n",
       " 'AVT',\n",
       " 'AVTR',\n",
       " 'AVXL',\n",
       " 'AVY',\n",
       " 'AVYA',\n",
       " 'AWI',\n",
       " 'AWK',\n",
       " 'AWR',\n",
       " 'AWRE',\n",
       " 'AX',\n",
       " 'AXAS',\n",
       " 'AXDX',\n",
       " 'AXGN',\n",
       " 'AXL',\n",
       " 'AXNX',\n",
       " 'AXP',\n",
       " 'AXR',\n",
       " 'AXS',\n",
       " 'AXSM',\n",
       " 'AXTA',\n",
       " 'AXTI',\n",
       " 'AYI',\n",
       " 'AYX',\n",
       " 'AZO',\n",
       " 'AZPN',\n",
       " 'AZZ',\n",
       " 'B',\n",
       " 'BA',\n",
       " 'BAC',\n",
       " 'BAH',\n",
       " 'BANC',\n",
       " 'BAND',\n",
       " 'BANF',\n",
       " 'BANR',\n",
       " 'BATRA',\n",
       " 'BATRK',\n",
       " 'BAX',\n",
       " 'BBBY',\n",
       " 'BBCP',\n",
       " 'BBGI',\n",
       " 'BBSI',\n",
       " 'BBW',\n",
       " 'BBY',\n",
       " 'BC',\n",
       " 'BCBP',\n",
       " 'BCC',\n",
       " 'BCLI',\n",
       " 'BCO',\n",
       " 'BCOR',\n",
       " 'BCOV',\n",
       " 'BCPC',\n",
       " 'BCRX',\n",
       " 'BDC',\n",
       " 'BDL',\n",
       " 'BDN',\n",
       " 'BDSI',\n",
       " 'BDX',\n",
       " 'BE',\n",
       " 'BECN',\n",
       " 'BELFA',\n",
       " 'BELFB',\n",
       " 'BEN',\n",
       " 'BERY',\n",
       " 'BFAM',\n",
       " 'BFIN',\n",
       " 'BFS',\n",
       " 'BFST',\n",
       " 'BG',\n",
       " 'BGCP',\n",
       " 'BGFV',\n",
       " 'BGS',\n",
       " 'BGSF',\n",
       " 'BH',\n",
       " 'BHB',\n",
       " 'BHE',\n",
       " 'BHF',\n",
       " 'BHLB',\n",
       " 'BHR',\n",
       " 'BHVN',\n",
       " 'BIG',\n",
       " 'BIIB',\n",
       " 'BIO',\n",
       " 'BIOC',\n",
       " 'BIOL',\n",
       " 'BJ',\n",
       " 'BJRI',\n",
       " 'BK',\n",
       " 'BKD',\n",
       " 'BKE',\n",
       " 'BKH',\n",
       " 'BKI',\n",
       " 'BKNG',\n",
       " 'BKSC',\n",
       " 'BKTI',\n",
       " 'BKU',\n",
       " 'BL',\n",
       " 'BLBD',\n",
       " 'BLCM',\n",
       " 'BLD',\n",
       " 'BLDR',\n",
       " 'BLFS',\n",
       " 'BLK',\n",
       " 'BLKB',\n",
       " 'BLL',\n",
       " 'BLMN',\n",
       " 'BLUE',\n",
       " 'BMI',\n",
       " 'BMRC',\n",
       " 'BMRN',\n",
       " 'BMY',\n",
       " 'BNED',\n",
       " 'BNFT',\n",
       " 'BOH',\n",
       " 'BOKF',\n",
       " 'BOOM',\n",
       " 'BOOT',\n",
       " 'BOTJ',\n",
       " 'BOX',\n",
       " 'BPMC',\n",
       " 'BPOP',\n",
       " 'BPRN',\n",
       " 'BPTH',\n",
       " 'BR',\n",
       " 'BRC',\n",
       " 'BRG',\n",
       " 'BRID',\n",
       " 'BRKL',\n",
       " 'BRKR',\n",
       " 'BRN',\n",
       " 'BRO',\n",
       " 'BRT',\n",
       " 'BRX',\n",
       " 'BRY',\n",
       " 'BSET',\n",
       " 'BSGM',\n",
       " 'BSQR',\n",
       " 'BSRR',\n",
       " 'BSX',\n",
       " 'BTN',\n",
       " 'BTU',\n",
       " 'BURL',\n",
       " 'BUSE',\n",
       " 'BV',\n",
       " 'BW',\n",
       " 'BWA',\n",
       " 'BWEN',\n",
       " 'BWFG',\n",
       " 'BWXT',\n",
       " 'BXC',\n",
       " 'BXMT',\n",
       " 'BXP',\n",
       " 'BY',\n",
       " 'BYD',\n",
       " 'BYFC',\n",
       " 'BYND',\n",
       " 'BZH',\n",
       " 'C',\n",
       " 'CABO',\n",
       " 'CAC',\n",
       " 'CACC',\n",
       " 'CACI',\n",
       " 'CADE',\n",
       " 'CAG',\n",
       " 'CAH',\n",
       " 'CAKE',\n",
       " 'CAL',\n",
       " 'CALA',\n",
       " 'CALM',\n",
       " 'CALX',\n",
       " 'CAMP',\n",
       " 'CAPR',\n",
       " 'CAR',\n",
       " 'CARA',\n",
       " 'CARG',\n",
       " 'CARS']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listdir returns all files in the directory and isfile will return true\n",
    "# if it is a file and then we store its name in our list named files\n",
    "files = [x for x in listdir(path) if isfile(join(path, x))]\n",
    "\n",
    "# Remove extension from file names\n",
    "# Splitext splits the file name into 2 parts being the name and extension\n",
    "# We say get all file names and then store just the name in our list named files\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe from our list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker\n",
       "0      A\n",
       "1     AA\n",
       "2    AAL\n",
       "3   AAME\n",
       "4    AAN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df = pd.DataFrame(tickers, columns=['Ticker'])\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that returns a dataframe from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a dataframe from the CSV file, changes index to date and returns it\n",
    "def getDF_fromCSV(ticker):\n",
    "    try:\n",
    "        df = pd.read_csv(path + ticker + '.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"File doesn't exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that saves dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDF_toCSV(df, ticker):\n",
    "    df.to_csv(path + ticker + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete unnamed columns in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unnamed_cols(df):\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add daily return to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate a percentage rate of return for each day to compare investments.\n",
    "# Simple Rate of Return = (End Price - Beginning Price) / Beginning Price OR (EP / BP) - 1\n",
    "\n",
    "# Shift provides the value from the previous day\n",
    "# NaN is displayed because there was no previous day price for the 1st calculation\n",
    "def add_dailyReturn_toDF(df, ticker):\n",
    "    df['daily_return'] = (df['Adj Close'] / df['Adj Close'].shift(1)) - 1\n",
    "    df.to_csv(path + ticker + '.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns ROI over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return on Investment is the return you received from your investment\n",
    "# This amount does not include your initial investment\n",
    "# If you invest 100 and have 200 after 5 years\n",
    "# ROI = End Value (200) - Initial Value (100) / Inital Value = 1\n",
    "# Your new total is Inital Investment + 1 * Inital Investment = 200\n",
    "\n",
    "def get_roi_defined_time(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date']) # Set as a datetime\n",
    "    start_value = df[df['Date'] == ST_DATE_STR]['Adj Close'][0]\n",
    "    print(\"Initial Price:\", start_value)\n",
    "    end_value = df[df['Date'] == EN_DATE_STR]['Adj Close']\n",
    "    print(end_value.item())\n",
    "    print(\"Final Price:\", end_value.item())\n",
    "    \n",
    "    # Calculate return on investment\n",
    "    roi = (end_value - start_value) / start_value\n",
    "    # Return the total return between 2 dates\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get coefficient of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives the dataframe with the Adj Close data and returns the coefficient of variation\n",
    "def get_cov(stock_df):\n",
    "    mean = stock_df['Adj Close'].mean()\n",
    "    sd = stock_df['Adj Close'].std()\n",
    "    cov = sd / mean\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>44.659351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>45.245331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>44.707394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>46.100292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>46.244377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Adj Close\n",
       "0  2017-01-03  44.659351\n",
       "1  2017-01-04  45.245331\n",
       "2  2017-01-05  44.707394\n",
       "3  2017-01-06  46.100292\n",
       "4  2017-01-09  46.244377"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_a = getDF_fromCSV(tickers[0])\n",
    "stock_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>44.659351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>45.245331</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>44.707394</td>\n",
       "      <td>-0.011889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>46.100292</td>\n",
       "      <td>0.031156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>46.244377</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Adj Close  daily_return\n",
       "0  2017-01-03  44.659351           NaN\n",
       "1  2017-01-04  45.245331      0.013121\n",
       "2  2017-01-05  44.707394     -0.011889\n",
       "3  2017-01-06  46.100292      0.031156\n",
       "4  2017-01-09  46.244377      0.003125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dailyReturn_toDF(stock_a, tickers[0])\n",
    "stock_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>44.659351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>45.245331</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>44.707394</td>\n",
       "      <td>-0.011889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>46.100292</td>\n",
       "      <td>0.031156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>46.244377</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Adj Close  daily_return\n",
       "0  2017-01-03  44.659351           NaN\n",
       "1  2017-01-04  45.245331      0.013121\n",
       "2  2017-01-05  44.707394     -0.011889\n",
       "3  2017-01-06  46.100292      0.031156\n",
       "4  2017-01-09  46.244377      0.003125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_a = delete_unnamed_cols(stock_a)\n",
    "stock_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDF_toCSV(stock_a, tickers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add daily returns & clean up all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on : A\n",
      "Working on : AA\n",
      "Working on : AAL\n",
      "Working on : AAME\n",
      "Working on : AAN\n",
      "Working on : AAOI\n",
      "Working on : AAON\n",
      "Working on : AAP\n",
      "Working on : AAPL\n",
      "Working on : AAT\n",
      "Working on : AAWW\n",
      "Working on : ABBV\n",
      "Working on : ABC\n",
      "Working on : ABCB\n",
      "Working on : ABEO\n",
      "Working on : ABG\n",
      "Working on : ABIO\n",
      "Working on : ABM\n",
      "Working on : ABMD\n",
      "Working on : ABR\n",
      "Working on : ABT\n",
      "Working on : ABTX\n",
      "Working on : AC\n",
      "Working on : ACA\n",
      "Working on : ACAD\n",
      "Working on : ACBI\n",
      "Working on : ACC\n",
      "Working on : ACCO\n",
      "Working on : ACER\n",
      "Working on : ACGL\n",
      "Working on : ACHC\n",
      "Working on : ACHV\n",
      "Working on : ACIW\n",
      "Working on : ACLS\n",
      "Working on : ACM\n",
      "Working on : ACMR\n",
      "Working on : ACN\n",
      "Working on : ACNB\n",
      "Working on : ACOR\n",
      "Working on : ACRE\n",
      "Working on : ACRS\n",
      "Working on : ACRX\n",
      "Working on : ACTG\n",
      "Working on : ACU\n",
      "Working on : ACY\n",
      "Working on : ADBE\n",
      "Working on : ADC\n",
      "Working on : ADES\n",
      "Working on : ADI\n",
      "Working on : ADM\n",
      "Working on : ADMA\n",
      "Working on : ADMP\n",
      "Working on : ADNT\n",
      "Working on : ADP\n",
      "Working on : ADS\n",
      "Working on : ADSK\n",
      "Working on : ADT\n",
      "Working on : ADTN\n",
      "Working on : ADUS\n",
      "Working on : ADVM\n",
      "Working on : ADXS\n",
      "Working on : AE\n",
      "Working on : AEE\n",
      "Working on : AEHR\n",
      "Working on : AEIS\n",
      "Working on : AEL\n",
      "Working on : AEMD\n",
      "Working on : AEO\n",
      "Working on : AEP\n",
      "Working on : AERI\n",
      "Working on : AES\n",
      "Working on : AEY\n",
      "Working on : AFG\n",
      "Working on : AFI\n",
      "Working on : AFL\n",
      "Working on : AGCO\n",
      "Working on : AGE\n",
      "Working on : AGEN\n",
      "Working on : AGFS\n",
      "Working on : AGIO\n",
      "Working on : AGLE\n",
      "Working on : AGM\n",
      "Working on : AGNC\n",
      "Working on : AGO\n",
      "Working on : AGR\n",
      "Working on : AGRX\n",
      "Working on : AGS\n",
      "Working on : AGTC\n",
      "Working on : AGX\n",
      "Working on : AGYS\n",
      "Working on : AHH\n",
      "Working on : AHT\n",
      "Working on : AIG\n",
      "Working on : AIMC\n",
      "Working on : AIN\n",
      "Working on : AINC\n",
      "Working on : AIR\n",
      "Working on : AIRG\n",
      "Working on : AIRI\n",
      "Working on : AIRT\n",
      "Working on : AIT\n",
      "Working on : AIV\n",
      "Working on : AIZ\n",
      "Working on : AJG\n",
      "Working on : AJRD\n",
      "Working on : AJX\n",
      "Working on : AKAM\n",
      "Working on : AKBA\n",
      "Working on : AKR\n",
      "Working on : AKTS\n",
      "Working on : AL\n",
      "Working on : ALB\n",
      "Working on : ALBO\n",
      "Working on : ALCO\n",
      "Working on : ALDX\n",
      "Working on : ALE\n",
      "Working on : ALEC\n",
      "Working on : ALEX\n",
      "Working on : ALG\n",
      "Working on : ALGN\n",
      "Working on : ALGT\n",
      "Working on : ALIM\n",
      "Working on : ALJJ\n",
      "Working on : ALK\n",
      "Working on : ALKS\n",
      "Working on : ALL\n",
      "Working on : ALLE\n",
      "Working on : ALLK\n",
      "Working on : ALLO\n",
      "Working on : ALLY\n",
      "Working on : ALNA\n",
      "Working on : ALNY\n",
      "Working on : ALOT\n",
      "Working on : ALPN\n",
      "Working on : ALRM\n",
      "Working on : ALSN\n",
      "Working on : ALT\n",
      "Working on : ALTR\n",
      "Working on : ALV\n",
      "Working on : ALX\n",
      "Working on : AM\n",
      "Working on : AMAL\n",
      "Working on : AMAT\n",
      "Working on : AMBC\n",
      "Working on : AMC\n",
      "Working on : AMCX\n",
      "Working on : AMD\n",
      "Working on : AME\n",
      "Working on : AMED\n",
      "Working on : AMG\n",
      "Working on : AMGN\n",
      "Working on : AMH\n",
      "Working on : AMKR\n",
      "Working on : AMN\n",
      "Working on : AMNB\n",
      "Working on : AMOT\n",
      "Working on : AMP\n",
      "Working on : AMPE\n",
      "Working on : AMPH\n",
      "Working on : AMRC\n",
      "Working on : AMRK\n",
      "Working on : AMRS\n",
      "Working on : AMRX\n",
      "Working on : AMS\n",
      "Working on : AMSC\n",
      "Working on : AMSF\n",
      "Working on : AMSWA\n",
      "Working on : AMT\n",
      "Working on : AMTD\n",
      "Working on : AMTX\n",
      "Working on : AMWD\n",
      "Working on : AMZN\n",
      "Working on : AN\n",
      "Working on : ANAB\n",
      "Working on : ANAT\n",
      "Working on : ANDE\n",
      "Working on : ANET\n",
      "Working on : ANF\n",
      "Working on : ANGI\n",
      "Working on : ANGO\n",
      "Working on : ANIK\n",
      "Working on : ANIP\n",
      "Working on : ANIX\n",
      "Working on : ANSS\n",
      "Working on : ANTM\n",
      "Working on : AON\n",
      "Working on : AOS\n",
      "Working on : AOSL\n",
      "Working on : AP\n",
      "Working on : APA\n",
      "Working on : APAM\n",
      "Working on : APD\n",
      "Working on : APDN\n",
      "Working on : APEI\n",
      "Working on : APEN\n",
      "Working on : APH\n",
      "Working on : APLE\n",
      "Working on : APLS\n",
      "Working on : APOG\n",
      "Working on : APPF\n",
      "Working on : APPN\n",
      "Working on : APPS\n",
      "Working on : APRN\n",
      "Working on : APT\n",
      "Working on : APTS\n",
      "Working on : APTV\n",
      "Working on : APVO\n",
      "Working on : APYX\n",
      "Working on : AQB\n",
      "Working on : AQMS\n",
      "Working on : AQUA\n",
      "Working on : AR\n",
      "Working on : ARAV\n",
      "Working on : ARAY\n",
      "Working on : ARC\n",
      "Working on : ARCB\n",
      "Working on : ARCH\n",
      "Working on : ARDX\n",
      "Working on : ARE\n",
      "Working on : ARES\n",
      "Working on : ARGO\n",
      "Working on : ARI\n",
      "Working on : ARKR\n",
      "Working on : ARL\n",
      "Working on : ARLO\n",
      "Working on : ARMK\n",
      "Working on : ARNA\n",
      "Working on : ARNC\n",
      "Working on : AROC\n",
      "Working on : AROW\n",
      "Working on : ARR\n",
      "Working on : ARTNA\n",
      "Working on : ARTW\n",
      "Working on : ARVN\n",
      "Working on : ARW\n",
      "Working on : ARWR\n",
      "Working on : ASB\n",
      "Working on : ASGN\n",
      "Working on : ASH\n",
      "Working on : ASIX\n",
      "Working on : ASMB\n",
      "Working on : ASPN\n",
      "Working on : ASPS\n",
      "Working on : ASRT\n",
      "Working on : ASRV\n",
      "Working on : ASTC\n",
      "Working on : ASTE\n",
      "Working on : ASUR\n",
      "Working on : ASYS\n",
      "Working on : ATEC\n",
      "Working on : ATEN\n",
      "Working on : ATGE\n",
      "Working on : ATHX\n",
      "Working on : ATI\n",
      "Working on : ATKR\n",
      "Working on : ATLC\n",
      "Working on : ATLO\n",
      "Working on : ATNI\n",
      "Working on : ATNM\n",
      "Working on : ATNX\n",
      "Working on : ATO\n",
      "Working on : ATOS\n",
      "Working on : ATR\n",
      "Working on : ATRA\n",
      "Working on : ATRC\n",
      "Working on : ATRI\n",
      "Working on : ATRO\n",
      "Working on : ATRS\n",
      "Working on : ATSG\n",
      "Working on : ATUS\n",
      "Working on : ATVI\n",
      "Working on : AUBN\n",
      "Working on : AUMN\n",
      "Working on : AUTO\n",
      "Working on : AVA\n",
      "Working on : AVAV\n",
      "Working on : AVB\n",
      "Working on : AVD\n",
      "Working on : AVEO\n",
      "Working on : AVGO\n",
      "Working on : AVGR\n",
      "Working on : AVID\n",
      "Working on : AVLR\n",
      "Working on : AVNS\n",
      "Working on : AVNW\n",
      "Working on : AVRO\n",
      "Working on : AVT\n",
      "Working on : AVTR\n",
      "Working on : AVXL\n",
      "Working on : AVY\n",
      "Working on : AVYA\n",
      "Working on : AWI\n",
      "Working on : AWK\n",
      "Working on : AWR\n",
      "Working on : AWRE\n",
      "Working on : AX\n",
      "Working on : AXAS\n",
      "Working on : AXDX\n",
      "Working on : AXGN\n",
      "Working on : AXL\n",
      "Working on : AXNX\n",
      "Working on : AXP\n",
      "Working on : AXR\n",
      "Working on : AXS\n",
      "Working on : AXSM\n",
      "Working on : AXTA\n",
      "Working on : AXTI\n",
      "Working on : AYI\n",
      "Working on : AYX\n",
      "Working on : AZO\n",
      "Working on : AZPN\n",
      "Working on : AZZ\n",
      "Working on : B\n",
      "Working on : BA\n",
      "Working on : BAC\n",
      "Working on : BAH\n",
      "Working on : BANC\n",
      "Working on : BAND\n",
      "Working on : BANF\n",
      "Working on : BANR\n",
      "Working on : BATRA\n",
      "Working on : BATRK\n",
      "Working on : BAX\n",
      "Working on : BBBY\n",
      "Working on : BBCP\n",
      "Working on : BBGI\n",
      "Working on : BBSI\n",
      "Working on : BBW\n",
      "Working on : BBY\n",
      "Working on : BC\n",
      "Working on : BCBP\n",
      "Working on : BCC\n",
      "Working on : BCLI\n",
      "Working on : BCO\n",
      "Working on : BCOR\n",
      "Working on : BCOV\n",
      "Working on : BCPC\n",
      "Working on : BCRX\n",
      "Working on : BDC\n",
      "Working on : BDL\n",
      "Working on : BDN\n",
      "Working on : BDSI\n",
      "Working on : BDX\n",
      "Working on : BE\n",
      "Working on : BECN\n",
      "Working on : BELFA\n",
      "Working on : BELFB\n",
      "Working on : BEN\n",
      "Working on : BERY\n",
      "Working on : BFAM\n",
      "Working on : BFIN\n",
      "Working on : BFS\n",
      "Working on : BFST\n",
      "Working on : BG\n",
      "Working on : BGCP\n",
      "Working on : BGFV\n",
      "Working on : BGS\n",
      "Working on : BGSF\n",
      "Working on : BH\n",
      "Working on : BHB\n",
      "Working on : BHE\n",
      "Working on : BHF\n",
      "Working on : BHLB\n",
      "Working on : BHR\n",
      "Working on : BHVN\n",
      "Working on : BIG\n",
      "Working on : BIIB\n",
      "Working on : BIO\n",
      "Working on : BIOC\n",
      "Working on : BIOL\n",
      "Working on : BJ\n",
      "Working on : BJRI\n",
      "Working on : BK\n",
      "Working on : BKD\n",
      "Working on : BKE\n",
      "Working on : BKH\n",
      "Working on : BKI\n",
      "Working on : BKNG\n",
      "Working on : BKSC\n",
      "Working on : BKTI\n",
      "Working on : BKU\n",
      "Working on : BL\n",
      "Working on : BLBD\n",
      "Working on : BLCM\n",
      "Working on : BLD\n",
      "Working on : BLDR\n",
      "Working on : BLFS\n",
      "Working on : BLK\n",
      "Working on : BLKB\n",
      "Working on : BLL\n",
      "Working on : BLMN\n",
      "Working on : BLUE\n",
      "Working on : BMI\n",
      "Working on : BMRC\n",
      "Working on : BMRN\n",
      "Working on : BMY\n",
      "Working on : BNED\n",
      "Working on : BNFT\n",
      "Working on : BOH\n",
      "Working on : BOKF\n",
      "Working on : BOOM\n",
      "Working on : BOOT\n",
      "Working on : BOTJ\n",
      "Working on : BOX\n",
      "Working on : BPMC\n",
      "Working on : BPOP\n",
      "Working on : BPRN\n",
      "Working on : BPTH\n",
      "Working on : BR\n",
      "Working on : BRC\n",
      "Working on : BRG\n",
      "Working on : BRID\n",
      "Working on : BRKL\n",
      "Working on : BRKR\n",
      "Working on : BRN\n",
      "Working on : BRO\n",
      "Working on : BRT\n",
      "Working on : BRX\n",
      "Working on : BRY\n",
      "Working on : BSET\n",
      "Working on : BSGM\n",
      "Working on : BSQR\n",
      "Working on : BSRR\n",
      "Working on : BSX\n",
      "Working on : BTN\n",
      "Working on : BTU\n",
      "Working on : BURL\n",
      "Working on : BUSE\n",
      "Working on : BV\n",
      "Working on : BW\n",
      "Working on : BWA\n",
      "Working on : BWEN\n",
      "Working on : BWFG\n",
      "Working on : BWXT\n",
      "Working on : BXC\n",
      "Working on : BXMT\n",
      "Working on : BXP\n",
      "Working on : BY\n",
      "Working on : BYD\n",
      "Working on : BYFC\n",
      "Working on : BYND\n",
      "Working on : BZH\n",
      "Working on : C\n",
      "Working on : CABO\n",
      "Working on : CAC\n",
      "Working on : CACC\n",
      "Working on : CACI\n",
      "Working on : CADE\n",
      "Working on : CAG\n",
      "Working on : CAH\n",
      "Working on : CAKE\n",
      "Working on : CAL\n",
      "Working on : CALA\n",
      "Working on : CALM\n",
      "Working on : CALX\n",
      "Working on : CAMP\n",
      "Working on : CAPR\n",
      "Working on : CAR\n",
      "Working on : CARA\n",
      "Working on : CARG\n",
      "Working on : CARS\n"
     ]
    }
   ],
   "source": [
    "# Create a backup for all original stock data\n",
    "\n",
    "# Cycle through all tickers\n",
    "for ticker in tickers:\n",
    "    print(\"Working on :\", ticker)\n",
    "    \n",
    "    # Get a dataframe for that ticker\n",
    "    stock_df = getDF_fromCSV(ticker)\n",
    "    \n",
    "    # Add daily return to this dataframe\n",
    "    add_dailyReturn_toDF(stock_df, ticker)\n",
    "    \n",
    "    # Delete unnamed columns in dataframe\n",
    "    stock_df = delete_unnamed_cols(stock_df)\n",
    "    \n",
    "    # Save cleaned dataframe to csv\n",
    "    saveDF_toCSV(stock_df, ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stock return over time period & coefficient of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Price: 44.65935134887695\n",
      "167.24119567871094\n",
      "Final Price: 167.24119567871094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1165    2.744819\n",
       "Name: Adj Close, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_a\n",
    "\n",
    "# Get total return since 2017\n",
    "# Final Price 167.67 = (44.77 * 2.745) + 44.77\n",
    "get_roi_defined_time(stock_a)\n",
    "\n",
    "# Get coefficient of variation \n",
    "# This is higher than normal because I'm using many years instead of one\n",
    "# get_cov(stock_a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d18b5a4e1ba12af76ae47ebb740da2f5baa5542ce1065cc0d011e76aa01f4f16"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
