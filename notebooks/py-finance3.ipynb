{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python for Finance 3 - Low Risk Investment Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides ways to work with large multidimensional arrays\n",
    "import numpy as np \n",
    "# Allows for further data manipulation and analysis\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as web # Reads stock data \n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import matplotlib.dates as mdates # Styling dates\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt # For defining dates\n",
    "import mplfinance as mpf # Matplotlib finance\n",
    "\n",
    "import time\n",
    "\n",
    "# Used to get data from a directory\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to files\n",
    "PATH = \"../data/stock-list/\"\n",
    "\n",
    "# Start date defaults\n",
    "ST_YEAR = 2017\n",
    "ST_MONTH = 1\n",
    "ST_DAY = 1\n",
    "ST_DATE_STR = f\"{ST_YEAR}-{ST_MONTH}-{ST_DAY}\"\n",
    "ST_DATE_DATETIME = dt.datetime(ST_YEAR, ST_MONTH, ST_DAY)\n",
    "\n",
    "# End date defaults\n",
    "EN_YEAR = 2021\n",
    "EN_MONTH = 12\n",
    "EN_DAY = 31\n",
    "EN_DATE_STR = f\"{EN_YEAR}-{EN_MONTH}-{EN_DAY}\"\n",
    "EN_DATE_DATETIME = dt.datetime(EN_YEAR, EN_MONTH, EN_DAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stock file names in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in listdir(PATH) if isfile(join(PATH, x))]\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers\n",
    "\n",
    "tickers.sort()\n",
    "tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that returns a dataframe from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a dataframe from the CSV file, changes index to date and returns it\n",
    "def get_df_from_csv(ticker):\n",
    "    # Try to get the file and if it doesn't exist issue a warning\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(\"File Doesn't Exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that saves dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(df, ticker):\n",
    "    df.to_csv(PATH + ticker + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return 1st valid date in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives a start and end date and returns the 1st date in that range\n",
    "def get_valid_dates(df, sdate, edate):\n",
    "    \n",
    "    try:\n",
    "        mask = (df['Date'] > sdate) & (df['Date'] <= edate) \n",
    "        sm_df = df.loc[mask]\n",
    "        sm_df = sm_df.set_index(['Date'])\n",
    "    \n",
    "        # Get smallest date that matches\n",
    "        sm_date = sm_df.index.min()\n",
    "        last_date = sm_df.index.max()\n",
    "    \n",
    "        # Add leading zeros to date\n",
    "        # Split string on - and if a number is less than 2 add a zero in front\n",
    "        date_leading = '-'.join(('0' if len(x)<2 else '')+x for x in sm_date.split('-'))\n",
    "        date_ending = '-'.join(('0' if len(x)<2 else '')+x for x in last_date.split('-'))\n",
    "        print(date_leading, \" \", date_ending)\n",
    "    except Exception:\n",
    "        print(\"Date Corrupted\")\n",
    "    else:\n",
    "        return date_leading, date_ending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returns ROI over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROI between 2 dates\n",
    "def roi_between_dates(df, sdate, edate):\n",
    "    \n",
    "    try:\n",
    "        # Gets the Adj Close price for 1st & last date \n",
    "        start_val = df.loc[sdate,'Adj Close'] \n",
    "        end_val = df.loc[edate,'Adj Close']\n",
    "        roi = ((end_val - start_val) / start_val)\n",
    "    except Exception:\n",
    "        print(\"Data Corrupted\")\n",
    "    else:\n",
    "        return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean between dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_between_dates(df, sdate, edate):\n",
    "    mask = (df['Date'] > sdate) & (df['Date'] <= edate)\n",
    "    return df.loc[mask][\"Adj Close\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get standard deviation between dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sd_between_dates(df, sdate, edate):\n",
    "    mask = (df['Date'] > sdate) & (df['Date'] <= edate)\n",
    "    return df.loc[mask][\"Adj Close\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get coefficient of variation between dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_between_dates(df, sdate, edate):\n",
    "    mean = get_mean_between_dates(df, sdate, edate)\n",
    "    sd = get_sd_between_dates(df, sdate, edate)\n",
    "    return sd / mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our 1st ticker\n",
    "tickers[0]\n",
    "print(\"Dataframe for Ticker\", tickers[0])\n",
    "\n",
    "# Get a dataframe for that ticker\n",
    "stock_a = get_df_from_csv(tickers[0])\n",
    "stock_a\n",
    "\n",
    "# Get the first and last valid date in the date range\n",
    "print(get_valid_dates(stock_a, '2020-01-01', '2020-12-31'))\n",
    "sdate, edate = get_valid_dates(stock_a, '2020-01-01', '2020-12-31')\n",
    "sdate\n",
    "edate\n",
    "\n",
    "print(\"Adj Close Mean :\", get_mean_between_dates(stock_a, sdate, edate))\n",
    "print(\"Adj Close Standard Deviation :\", get_sd_between_dates(stock_a, sdate, edate))\n",
    "print(\"Adj Close Coefficient of Variation :\", get_cov_between_dates(stock_a, sdate, edate))\n",
    "\n",
    "stock_a = stock_a.set_index(['Date'])\n",
    "stock_a\n",
    "\n",
    "print(\"Return on Investment since 2020:\", roi_between_dates(stock_a, sdate, edate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COV & ROI for all stocks over defined period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov_ror(tickers, sdate, edate):\n",
    "    # Define column names for dataframe\n",
    "    col_names = [\"Ticker\", \"COV\", \"ROI\"]\n",
    "    \n",
    "    # Create dataframe with column names\n",
    "    df = pd.DataFrame(columns = col_names)\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(\"Working on :\", ticker)\n",
    "        s_df = get_df_from_csv(ticker)\n",
    "    \n",
    "        sdate2, edate2 = get_valid_dates(s_df, sdate, edate)\n",
    "    \n",
    "        cov = get_cov_between_dates(s_df, sdate2, edate2)\n",
    "    \n",
    "        # Set date as index\n",
    "        s_df = s_df.set_index(['Date'])\n",
    "        roi = roi_between_dates(s_df, sdate2, edate2)\n",
    "\n",
    "        # Add stock data to new dataframe row\n",
    "        # len provides the length of the dataframe which is the next open index\n",
    "        df.loc[len(df.index)] = [ticker, cov, roi]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the time period, remove some data\n",
    "# In this case: BEAT CHK GPOR NE SMRT VAL\n",
    "market_df = get_cov_ror(tickers, '2020-01-01', '2020-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 20 stocks ROI\n",
    "market_df.sort_values(by=['ROI'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge multiple stocks in one dataframe by column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_by_column_name(col_name, sdate, edate, *tickers):\n",
    "    # Will hold data for all dataframes with the same column name\n",
    "    mult_df = pd.DataFrame()\n",
    "    \n",
    "    for x in tickers:\n",
    "        df = get_df_from_csv(x)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        # Use a mask to grab data between defined dates\n",
    "        mask = (df['Date'] >= sdate) & (df['Date'] <= edate)\n",
    "        mult_df[x] = df.loc[mask][col_name]\n",
    "        \n",
    "    return mult_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a correlation matrix using FAANGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation tells us how closely 2 stocks returns move together\n",
    "# Correlation is a standardized value lying between -1 and 1\n",
    "# When this value is greater that .5 we say that these stocks are strongly correlated\n",
    "# Of course each stocks price is perfectly correlated with itself\n",
    "\n",
    "# We focus on the correlation of returns because investors care about returns \n",
    "\n",
    "# Merge all stock price data into 1 dataframe\n",
    "faang_list = [\"FB\", \"AMZN\", \"AAPL\", \"NFLX\", \"GOOG\"]\n",
    "mult_df = merge_df_by_column_name('daily_return',  '2020-1-1', '2020-12-31', *faang_list)\n",
    "mult_df\n",
    "\n",
    "# Generate a Correlation Matrix\n",
    "mult_df.corr()\n",
    "\n",
    "# We can look at the correlation between Netflix and the others\n",
    "mult_df.corr()['NFLX']\n",
    "\n",
    "# We can plot this in a bar chart\n",
    "mult_df.corr()['NFLX'].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the variance of a stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember variance is a measure of how spread out a data set is\n",
    "# Get Netflix variance\n",
    "mult_df['NFLX'].var()\n",
    "\n",
    "# Annualize by getting the number of samples and multiply\n",
    "days = len(mult_df.index) # 253\n",
    "\n",
    "nflx_a_var = mult_df['NFLX'].var() * 253\n",
    "nflx_a_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get covariance of stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_df.cov() * 253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we care about risk\n",
    "\n",
    "Most investors don't handle massive flucuations in stock prices well. What we want to do at the very least is to make them aware of how dramatically their portfolios returns may be. We can then do our best to minimize risk by adding other stocks that have returns that aren't as closely correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a portfolios variance\n",
    "\n",
    "When calculating the variance of a portfolio we must define its weight, or how much of the portfolio it makes up. If you add up the weight of all stocks you get a value of 1.\n",
    "\n",
    "$ w_1, w_2 $ = Stock Weights\n",
    "\n",
    "$ \\sigma_1, \\sigma_2 $ = Stock Standard Deviations\n",
    "\n",
    "Portfolio Variance = $ (w_1 \\sigma_1 + w_2 \\sigma_2)^2 $\n",
    "\n",
    "Since $ (a+b)^2 = a^2 + 2ab + b^2 $\n",
    "\n",
    "Then the Portfolio Variance = $ w_1^2 \\sigma_1^2 + w_1 \\sigma_1 w_2 \\sigma_2 \\rho_12 + w_2^2 \\sigma_2^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a portfolio made up of Facebook & Newmont Corporation\n",
    "port_list = [\"FB\", \"NEM\"]\n",
    "port_df = merge_df_by_column_name('daily_return',  '2020-1-1', '2020-12-31', *port_list)\n",
    "port_df\n",
    "\n",
    "# Generate a Correlation Matrix to see that they are not correlated\n",
    "port_df.corr()\n",
    "\n",
    "# Get prices at the beginning of Jan 2020 to calculate weight of both stocks\n",
    "price_df = merge_df_by_column_name('Adj Close',  '2020-1-1', '2020-12-31', *[\"FB\",\"NEM\"])\n",
    "price_df.head()\n",
    "\n",
    "# I'll buy 1 share of FB at 209.78 & 5 of NEM for 41.74 for a total of 208.70\n",
    "# Total Value = $418.48\n",
    "fb_wt = 209.78 / 418.48\n",
    "nem_wt = 208.70 / 418.48\n",
    "fb_wt = .5012 # .5012\n",
    "nem_wt = .4988 # .4987 and we'll change it to .4988 so they equal 1\n",
    "wts = np.array([fb_wt, nem_wt])\n",
    "\n",
    "# The portfolio variance is found from matrix multiplication\n",
    "# We transpose the weights, multiply by the covarience and then the weight to get \n",
    "# the covariance of the portfolio\n",
    "wts.T\n",
    "port_var = np.dot(wts.T, np.dot(port_df.cov() * 253, wts))\n",
    "print(\"Portfolio Var :\", port_var)\n",
    "print(\"FB Var :\", port_df[\"FB\"].var() * 253)\n",
    "print(\"NEM Var :\", port_df[\"NEM\"].var() * 253)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feac5ee11db6385b4c12b0947c117f22892e921fb5655ece65f725e09c2e67f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('finance')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
